{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ky2zpklwpN1W"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgroth/deephys-aio/blob/master/Python_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Extract Neural Activity (example with Torch)\n",
        "\n",
        "Desired output:\n",
        "\n",
        "    [all_activs,all_outputs], #Lists with neural activity\n",
        "    all_images, #Images resized to 32x32 pixels\n",
        "    all_cats #Labels"
      ],
      "metadata": {
        "id": "Ky2zpklwpN1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n"
      ],
      "metadata": {
        "id": "VtUgz8xGYKHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Argument initializatio\n",
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=128\n",
        "args['cuda']=True #Enabling cuda is required"
      ],
      "metadata": {
        "id": "-yE0Wi_2zacR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural network model definition (Different ResNet versions)\n",
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear1 = nn.Linear(512*block.expansion, 50)\n",
        "        self.linear2 = nn.Linear(50, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n"
      ],
      "metadata": {
        "id": "EDUvllEtjjlJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please download [this Google Drive file](https://drive.google.com/file/d/1oUMHbE9ck1Wgi_C-RwmnP_w64IFdL3uK/view?usp=sharing) (`cifar_resnet18.pth`) and [this one](https://drive.google.com/file/d/1VtgCfn5YqYs1zJPyj6b5suv_xHlpJ_K1/view?usp=sharing) (`cifar102_train.npz`) too to continue\n",
        "\n",
        "Or use PyDrive below (tutorial reference [link text](https://sigmundojr.medium.com/how-do-i-read-a-csv-file-from-google-drive-using-python-colab-966091922852))"
      ],
      "metadata": {
        "id": "23nRK0aFWU1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileDownloaded = drive.CreateFile({\"id\":\"1oUMHbE9ck1Wgi_C-RwmnP_w64IFdL3uK\"})\n",
        "fileDownloaded.GetContentFile(\"cifar_resnet18.pth\")\n",
        "fileDownloaded = drive.CreateFile({\"id\":\"1VtgCfn5YqYs1zJPyj6b5suv_xHlpJ_K1\"})\n",
        "fileDownloaded.GetContentFile(\"cifar102_train.npz\")"
      ],
      "metadata": {
        "id": "mz_PWbyLXKr9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the activations for penultimate layer\n",
        "\n",
        "#Select a model\n",
        "models = ResNet18()\n",
        "if args['cuda']:\n",
        "    models.cuda()\n",
        "\n",
        "#Load the saved model\n",
        "state_dict = torch.load('cifar_resnet18.pth')\n",
        "models.load_state_dict(state_dict)\n",
        "\n",
        "#Function to extract activations and the logits\n",
        "from collections import defaultdict\n",
        "def act_extract(testloader, model):\n",
        "    all_activs = []\n",
        "    all_outputs = []\n",
        "    all_images = []\n",
        "    all_cats = []\n",
        "    activation = {}\n",
        "    #Standard normalization for CIFAR10 versions\n",
        "    normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    # resize = transforms.Resize((32,32)) #default size is 32 for deephys\n",
        "    a_s = defaultdict(list)\n",
        "    iterator = iter(testloader)\n",
        "    \n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "    \n",
        "    for i in range(len(testloader)):\n",
        "        # print (i)\n",
        "        data, target = next(iterator)\n",
        "\n",
        "        all_images.append(data)\n",
        "        all_cats.append(target)\n",
        "\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data = normalize(data) #Required to capture activations with normalized data\n",
        "\n",
        "        model.linear1.register_forward_hook(get_activation('linear1'))\n",
        "        with torch.no_grad():\n",
        "            activation['output'] = model(data).detach().cpu()#.numpy()\n",
        "            all_outputs.append(activation['output'])\n",
        "            activation['linear1'] = F.relu(activation['linear1']).detach().cpu()#.numpy()\n",
        "            all_activs.append(activation['linear1'])\n",
        "            \n",
        "    all_activs = torch.cat(all_activs)\n",
        "    all_outputs = torch.cat(all_outputs)\n",
        "    all_images = torch.cat(all_images)\n",
        "    all_cats = torch.cat(all_cats).numpy().tolist()\n",
        "    \n",
        "    return all_activs, all_outputs, all_images, all_cats"
      ],
      "metadata": {
        "id": "8VwDhs0jkMAW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=args['batch_size'],\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "all_activs, all_outputs, all_images, all_cats = act_extract(testloader, models)"
      ],
      "metadata": {
        "id": "xMBnjopzi_vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Collect neuron activations of penultimate layer for CIFAR10.2 for further experiments\n",
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "test_data = np.load('cifar102_train.npz')\n",
        "\n",
        "test_data_2 = np.transpose(test_data['images'], (0, 3, 1, 2))/255. #Required before the images can be fed to the model\n",
        "\n",
        "test_data_2 = TensorDataset(torch.FloatTensor(test_data_2), torch.LongTensor(test_data['labels']))\n",
        "testloader_2 = torch.utils.data.DataLoader(test_data_2,\n",
        "    batch_size=args['batch_size'], shuffle=False, **kwargs)\n",
        "\n",
        "all_activs_2, all_outputs_2, all_images_2, all_cats_2 = act_extract(testloader_2, models)"
      ],
      "metadata": {
        "id": "23cwdds78CgB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Save Neural Activity for the App"
      ],
      "metadata": {
        "id": "GpmXD_MSpd7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deephys==0.7.2\n",
        "from deephys import import_test_data, Neuron, Layer, Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UO0wyn2CViHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Declare the model**"
      ],
      "metadata": {
        "id": "PkZ_J9f90R86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare penultimate layer\n",
        "neuronList = []\n",
        "for i in range(np.shape(all_activs)[1]):\n",
        "  neuronList.append(Neuron())\n",
        "\n",
        "layerList = []\n",
        "layerList.append(Layer(\n",
        "    layerID = \"linear1\",\n",
        "    neurons = neuronList\n",
        "))\n",
        "\n",
        "# Declare output layer\n",
        "neuronList = []\n",
        "for i in range(np.shape(all_outputs)[1]):\n",
        "  neuronList.append(Neuron())\n",
        "\n",
        "layerList.append(Layer(\n",
        "    layerID = \"classification\",\n",
        "    neurons = neuronList\n",
        "))\n",
        "\n",
        "\n",
        "# Deephys model\n",
        "model = Model(\n",
        "    name = \"resnet18_cifar\",\n",
        "    suffix = None,\n",
        "    layers = layerList\n",
        ")\n",
        "\n",
        "model.save()"
      ],
      "metadata": {
        "id": "bcEBrF-WYOKI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save data for deephys**"
      ],
      "metadata": {
        "id": "OzG3e1wO2WMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Save CIFAR10\n",
        "test = import_test_data(\n",
        "    \"CIFAR10\",\n",
        "    classes,  #List with all category names\n",
        "    [all_activs,all_outputs], #List with neural activity\n",
        "    model, #Structure describing the model (see documentation)\n",
        "    all_images, #Images resized to 32x32 pixels\n",
        "    all_cats.numpy().tolist() #Labels\n",
        "    )\n",
        "test.suffix = None\n",
        "test.save()\n",
        "\n",
        "# Save CIFAR10v2\n",
        "test = import_test_data(\n",
        "    \"CIFARV2\",\n",
        "    classes,\n",
        "    [all_activs_2,all_outputs_2],\n",
        "    model,\n",
        "    all_images_2,\n",
        "    all_cats_2.numpy().tolist()\n",
        "    )\n",
        "test.suffix = None\n",
        "test.save()"
      ],
      "metadata": {
        "id": "fXw9BgDdmTZs"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}